{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "data = pd.read_csv(\"/content/modified_ielts_writing_dataset .csv\")\n",
        "\n",
        "\n",
        "# Step 2: Prepare the Data\n",
        "X = data['Question'] + \" \" + data['Essay']\n",
        "y = data['Overall']  # Assuming 'overall' is the target variable\n",
        "\n",
        "# Step 3: Tokenization and Padding\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_seq = tokenizer.texts_to_sequences(X)\n",
        "X_pad = pad_sequences(X_seq, maxlen=500)  # maxlen is the length of the longest sequence\n",
        "\n",
        "# Step 4: Split the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Define the LSTM Model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=500))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(1, activation='linear'))  # Linear activation function for regression task\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LkJmIKk710OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Step 6: Train the Model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n"
      ],
      "metadata": {
        "id": "PNG8a30V2KZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d215d5-bf91-43aa-8909-bdd7888236b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "17/17 [==============================] - 11s 471ms/step - loss: 36.4656 - val_loss: 4.6382\n",
            "Epoch 2/20\n",
            "17/17 [==============================] - 7s 415ms/step - loss: 1.8044 - val_loss: 1.2318\n",
            "Epoch 3/20\n",
            "17/17 [==============================] - 8s 469ms/step - loss: 1.2278 - val_loss: 1.0209\n",
            "Epoch 4/20\n",
            "17/17 [==============================] - 7s 403ms/step - loss: 1.1696 - val_loss: 0.9524\n",
            "Epoch 5/20\n",
            "17/17 [==============================] - 8s 470ms/step - loss: 1.1519 - val_loss: 0.9482\n",
            "Epoch 6/20\n",
            "17/17 [==============================] - 7s 426ms/step - loss: 1.1428 - val_loss: 0.9469\n",
            "Epoch 7/20\n",
            "17/17 [==============================] - 7s 426ms/step - loss: 1.1347 - val_loss: 0.9395\n",
            "Epoch 8/20\n",
            "17/17 [==============================] - 8s 472ms/step - loss: 1.1033 - val_loss: 0.9291\n",
            "Epoch 9/20\n",
            "17/17 [==============================] - 7s 411ms/step - loss: 1.0592 - val_loss: 0.9153\n",
            "Epoch 10/20\n",
            "17/17 [==============================] - 8s 476ms/step - loss: 1.0000 - val_loss: 0.8929\n",
            "Epoch 11/20\n",
            "17/17 [==============================] - 7s 438ms/step - loss: 0.9186 - val_loss: 0.8719\n",
            "Epoch 12/20\n",
            "17/17 [==============================] - 8s 428ms/step - loss: 0.8265 - val_loss: 0.8498\n",
            "Epoch 13/20\n",
            "17/17 [==============================] - 8s 472ms/step - loss: 0.7170 - val_loss: 0.8314\n",
            "Epoch 14/20\n",
            "17/17 [==============================] - 7s 416ms/step - loss: 0.6124 - val_loss: 0.8323\n",
            "Epoch 15/20\n",
            "17/17 [==============================] - 8s 475ms/step - loss: 0.5343 - val_loss: 0.8381\n",
            "Epoch 16/20\n",
            "17/17 [==============================] - 7s 442ms/step - loss: 0.4734 - val_loss: 0.8513\n",
            "Epoch 17/20\n",
            "17/17 [==============================] - 7s 421ms/step - loss: 0.4350 - val_loss: 0.8623\n",
            "Epoch 18/20\n",
            "17/17 [==============================] - 8s 480ms/step - loss: 0.4072 - val_loss: 0.8935\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d662c913be0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate the Model\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n"
      ],
      "metadata": {
        "id": "rbNBEiKA2MX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b6e07d-70bc-48ff-f9ae-37763fb73ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 75ms/step\n",
            "Mean Absolute Error: 0.8107861791338239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing question and answer in the dataset"
      ],
      "metadata": {
        "id": "4dgFLsfMeHwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_question = \"The bar chart below describes some changes about the percentage of people were born in Australia and who were born outside Australia living in urban, rural and town between 1995 and 2010.Summarise the information by selecting and reporting the main features and make comparisons where relevant.\"\n",
        "user_answer = \"Between 1995 and 2010, a study was conducted representing the percentages of people born in Australia, versus people born outside Australia, living in urban, rural, and town. First, in 1995, cities represented the major percentage of habitat by roughly 50 percent, followed by rural areas and towns came in last, among people born in Australia. On the other hand, people born outside Australia, cities showed the most percentages of 60 percent, followed by rural areas and towns. In 2010, among people born in Australia, cities had an increase more than 20 percent increase in the total representation and a major decrease in towns and rural areas. Conversely, people born outside Australia, cities had the most percentage among both studies, followed by rural areas and towns.\"\n",
        "\n",
        "new_input_text = new_question + \" \" + user_answer\n",
        "\n",
        "# Tokenize and pad the new input text\n",
        "new_input_seq = tokenizer.texts_to_sequences([new_input_text])\n",
        "new_input_pad = pad_sequences(new_input_seq, maxlen=500)  # Use the same maxlen as during training\n",
        "\n",
        "# Predict the score for the new input text\n",
        "predicted_score = model.predict(new_input_pad)\n",
        "print(\"Predicted Score:\", predicted_score[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYA1CWgg37sk",
        "outputId": "a83da8f3-06d1-4e2f-8c08-4f77f3549819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n",
            "Predicted Score: 5.6314654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing question and answer in the dataset"
      ],
      "metadata": {
        "id": "I2NyReiFp50R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_question = \"The bar chart below describes some changes about the percentage of people were born in Australia and who were born outside Australia living in urban, rural and town between 1995 and 2010.Summarise the information by selecting and reporting the main features and make comparisons where relevant.\"\n",
        "user_answer = \"The left chart shows the population change happened in Austrilia from 1995 to 2010. In 1995, half of the people born in australia are from cities, 30% from rural areas and only 20% are from towns. For the people outside of Australia, most of the people still born in cities, which is around 60%. but the number of rural areas increased to 40% with the towns born rate decreased to only 10%.In 2010, The people born in cities increased significianly in both in and outside Australia, especially in outside Australia, which reached 80%. The people bore in towns decreased simutanuously, to around 17% of the people born in Australia and 10% of outside Australia respectively. The most significiant change happened at rual areas numbers. It has shrinked to 17% of people born in Australia, and only around 5% of peopel bore outside Australia.Overall, the chart shows us the trend that many people moved to Cities from rual area in the past 15 years.\"\n",
        "\n",
        "new_input_text = new_question + \" \" + user_answer\n",
        "\n",
        "# Tokenize and pad the new input text\n",
        "new_input_seq = tokenizer.texts_to_sequences([new_input_text])\n",
        "new_input_pad = pad_sequences(new_input_seq, maxlen=500)  # Use the same maxlen as during training\n",
        "\n",
        "# Predict the score for the new input text\n",
        "predicted_score = model.predict(new_input_pad)\n",
        "print(\"Predicted Score:\", predicted_score[0][0])"
      ],
      "metadata": {
        "id": "iEnDmcb3ezVk",
        "outputId": "2997d3d1-6175-4d42-b486-de1da1cdadf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n",
            "Predicted Score: 6.5379605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing question and answer in the dataset"
      ],
      "metadata": {
        "id": "WlbQlJIYqLmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_question = \"Some countries achieve international sports by building specialised facilities to train top athletes, instead of providing sports facilities that everyone can use. Do you think this is positive or negative development?Discuss both views and give your opinion.\"\n",
        "user_answer = \"Athletes to be on the top need to have high-end facilities that a country can provide for them to be able to improve their strengths and skills. Some government opted to build facilities exclusively for training athletes for international sports goals, instead of building establishments for everyone to have the liberty of using the sports facilities. From my perspective, this phenomena is a negative development.Being able to discover an individual's potential, they need to have a support from any form of sources. Establishing sports facilities can help people to discover their own interests, talents and even skills in learning new things. Centers which offer utilities, equipments and state-of-the-art tools that provide learning sports can be a great advantage to people who want to train themselves on the things that can awaken their interests when it comes to sports.In addition, building these kind of establishments, not only for the purpose to train top athletes, but also for people to immerse themselves to different variaties of activities can help them socialize more with their peers. This is extremely beneficial that aside from doing sports that they are into, they get to play along with peers, discover one's potential and also learning from one another. Furthermore, these individuals can also have the future to be one of top athletes that a country can have.In conclusion, although there are countries that chose to have their sports establishments exclusively for training top athletes, I assert that these that actions can be lead to negative feedbacks. Government should allow everyone the privilege to use and avail facilities that can hone an individual's talents, skills and dexterity when it comes to sports and this can also be immensely benefical for both country and citizen alike.\"\n",
        "\n",
        "new_input_text = new_question + \" \" + user_answer\n",
        "\n",
        "# Tokenize and pad the new input text\n",
        "new_input_seq = tokenizer.texts_to_sequences([new_input_text])\n",
        "new_input_pad = pad_sequences(new_input_seq, maxlen=500)  # Use the same maxlen as during training\n",
        "\n",
        "# Predict the score for the new input text\n",
        "predicted_score = model.predict(new_input_pad)\n",
        "print(\"Predicted Score:\", predicted_score[0][0])"
      ],
      "metadata": {
        "id": "DGscFH02fkvz",
        "outputId": "5733b42d-2d04-4547-be89-f338607fa0f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 55ms/step\n",
            "Predicted Score: 5.521077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing question in the dataset and user's answer"
      ],
      "metadata": {
        "id": "yfPu80GrqYeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_question = \"Some countries achieve international sports by building specialised facilities to train top athletes, instead of providing sports facilities that everyone can use. Do you think this is positive or negative development?Discuss both views and give your opinion.\"\n",
        "user_answer = \"Constructing specialized sports facilities to train elite athletes raises concerns regarding equity and access for the broader population. While such investments may enhance a country's international sporting success, prioritizing elite training facilities over public access to sports facilities may exacerbate inequalities and limit opportunities for participation in sports among the general populace.\"\n",
        "\n",
        "new_input_text = new_question + \" \" + user_answer\n",
        "\n",
        "# Tokenize and pad the new input text\n",
        "new_input_seq = tokenizer.texts_to_sequences([new_input_text])\n",
        "new_input_pad = pad_sequences(new_input_seq, maxlen=500)  # Use the same maxlen as during training\n",
        "\n",
        "# Predict the score for the new input text\n",
        "predicted_score = model.predict(new_input_pad)\n",
        "print(\"Predicted Score:\", predicted_score[0][0])"
      ],
      "metadata": {
        "id": "SIaatibRkB9M",
        "outputId": "a3c3a969-715c-4f91-9887-071d9f463513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 52ms/step\n",
            "Predicted Score: 6.5802865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing question in the dataset and user's answer"
      ],
      "metadata": {
        "id": "Ib-LG2isej1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_question = \"The bar chart below describes some changes about the percentage of people were born in Australia and who were born outside Australia living in urban, rural and town between 1995 and 2010.Summarise the information by selecting and reporting the main features and make comparisons where relevant.\"\n",
        "user_answer = \"The bar chart illustrates shifts in the residential distribution of individuals born in Australia and abroad across urban, rural, and town areas from 1995 to 2010. Key observations reveal urban habitation predominance, notably increasing for Australian-born citizens. Conversely, rural and town residence declines are evident over the studied period.\"\n",
        "\n",
        "new_input_text = new_question + \" \" + user_answer\n",
        "\n",
        "# Tokenize and pad the new input text\n",
        "new_input_seq = tokenizer.texts_to_sequences([new_input_text])\n",
        "new_input_pad = pad_sequences(new_input_seq, maxlen=500)  # Use the same maxlen as during training\n",
        "\n",
        "# Predict the score for the new input text\n",
        "predicted_score = model.predict(new_input_pad)\n",
        "print(\"Predicted Score:\", predicted_score[0][0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "89UkR6Gx5fHs",
        "outputId": "8aeacb90-ff80-44ff-e646-46a76bf3f455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "Predicted Score: 6.914455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing question in the dataset and user's answer"
      ],
      "metadata": {
        "id": "IXb6SZeJqfj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing question and answer in the dataset"
      ],
      "metadata": {
        "id": "DpiF3vQAqz6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_question = \"Nowadays, not enough students choose science subjects in university in many countries. What are the reasons for this problem? What are the effects on society?\"\n",
        "user_answer = \"In recent years, many countries have reported a decrease in the number of students choosing science subjects in universities. This is a concerning trend that can have a profound impact on society. In this essay, I will discuss the reasons behind this problem and its implications.The first reason for fewer students selecting science subjects is likely that these courses are difficult to comprehend. In general, science courses such as mathematics and physics involve complex theories, formulas, and concepts that require a great deal of hard work to understand. Furthermore, they are often taught in a theoretical manner and fail to show students how this knowledge can be used in real life. In other words, it may seem impractical for them to learn science courses. Lastly, it may be hard to acquire a practical job through these theoretical subjects in the future. As a result, students may give up studying science because they find scientific studies unappealing, impractical, and not promising for their future careers.Consequently, the lack of students studying science subjects can have a significant impact on society. First and foremost, there may not be enough qualified scientists and teachers to teach the theoretical foundation of technology, medicine, and engineering. This could lead to slow progress in these areas, and society may suffer as a result. Moreover, the decline in the number of science students could lead to a shortage of scientists for research and development in industry, which would have a negative impact on the nation's economy.To sum up, the decreasing number of students selecting science courses in universities is a worrying phenomenon. The main reasons for this are the difficulty of science courses and the lack of job opportunities in science after studies. This could have a negative impact on society, as there may not be enough qualified scientists to pursue research, and this could impede progress in fields such as technology and medicine.\"\n",
        "\n",
        "# Tokenize and pad the new input text\n",
        "new_input_seq = tokenizer.texts_to_sequences([new_input_text])\n",
        "new_input_pad = pad_sequences(new_input_seq, maxlen=500)  # Use the same maxlen as during training\n",
        "\n",
        "# Predict the score for the new input text\n",
        "predicted_score = model.predict(new_input_pad)\n",
        "print(\"Predicted Score:\", predicted_score[0][0])"
      ],
      "metadata": {
        "id": "EdtLtGtFm39d",
        "outputId": "ec53be87-24d0-4fb1-c926-011a52988cf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 46ms/step\n",
            "Predicted Score: 7.1203666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the question in the dataset and giving the answer that does not match this question in the dataset"
      ],
      "metadata": {
        "id": "E3cKOMwfrA5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_question = \"Nowadays, not enough students choose science subjects in university in many countries. What are the reasons for this problem? What are the effects on society?\"\n",
        "user_answer = \"The two diagrams compare the proportion of time spent by adult workers in a specific country on different activities over a 50-year period, from 1958 to 2008.Overall, it can clearly be seen that in 1958, adult workers divided their time roughly equally between work, sleep, and other activities. However, over the next five decades, there was a remarkable increase in working hours, a significant decrease in sleep time, and the total time allocated to other activities remained nearly unchanged.It is surprising that adult workers spent almost the same amount of time sleeping (32%) as they did working (33%) in 1958. However, by 2008, they slept 7% less (25%) and worked 9% more (42%), which represents a remarkable increase in working hours. As a result, the time they spent at home for relaxation increased from 8% to 13%. In contrast, the time spent going out with friends and family declined dramatically by one-third, from 19% to 6%. The most striking change, however, was the significant increase in time spent traveling to work, which quadrupled from 2% to 8% over the 50 years.\"\n",
        "new_input_text = new_question + \" \" + user_answer\n",
        "\n",
        "# Tokenize and pad the new input text\n",
        "new_input_seq = tokenizer.texts_to_sequences([new_input_text])\n",
        "new_input_pad = pad_sequences(new_input_seq, maxlen=500)  # Use the same maxlen as during training\n",
        "\n",
        "# Predict the score for the new input text\n",
        "predicted_score = model.predict(new_input_pad)\n",
        "print(\"Predicted Score:\", predicted_score[0][0])"
      ],
      "metadata": {
        "id": "8q6stU8ZoXoi",
        "outputId": "5d785b02-292f-4a59-b1af-9906222052b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n",
            "Predicted Score: 6.739277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "data = pd.read_csv(\"/content/modified_ielts_writing_dataset .csv\")\n",
        "\n",
        "# Step 2: Prepare the Data\n",
        "data.dropna(subset=['Question', 'Essay', 'Overall'], inplace=True)  # Remove rows with missing values\n",
        "X = data['Question'] + \" \" + data['Essay']\n",
        "y = data['Overall']\n",
        "\n",
        "# Step 3: Tokenization and Padding\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_seq = tokenizer.texts_to_sequences(X)\n",
        "X_pad = pad_sequences(X_seq, maxlen=500)\n",
        "\n",
        "# Step 4: Split the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Define the LSTM Model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=500))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Step 6: Train the Model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Example user's answer\n",
        "user_answer = \"Between 1995 and 2010, a study was conducted representing the percentages of people born in Australia, versus people born outside Australia, living in urban, rural, and town. First, in 1995, cities represented the major percentage of habitat by roughly 50 percent, followed by rural areas and towns came in last, among people born in Australia. On the other hand, people born outside Australia, cities showed the most percentages of 60 percent, followed by rural areas and towns. In 2010, among people born in Australia, cities had an increase more than 20 percent increase in the total representation and a major decrease in towns and rural areas. Conversely, people born outside Australia, cities had the most percentage among both studies, followed by rural areas and towns.\"\n",
        "\n",
        "# Preprocess user's answer\n",
        "preprocessed_user_answer = preprocess_text(user_answer)\n",
        "\n",
        "# Calculate vocabulary rate\n",
        "user_tokens = word_tokenize(preprocessed_user_answer)\n",
        "vocab_rate = len(set(user_tokens)) / len(user_tokens)\n",
        "\n",
        "# Predicted grammar rate (example with a random value)\n",
        "def calculate_grammar_rate(answer):\n",
        "    # Count grammatical errors (this is a simplistic example)\n",
        "    # You may need a more sophisticated approach or use NLP tools for this task\n",
        "    num_errors = 0\n",
        "    # Example: Count number of sentences ending with punctuation other than period\n",
        "    num_errors += answer.count(\";\")  # Example: Count semicolons as errors\n",
        "    num_errors += answer.count(\",\")  # Example: Count commas as errors\n",
        "    return 1 - (num_errors / len(answer))  # Return grammar rate (normalized)\n",
        "\n",
        "\n",
        "def calculate_vocabulary_rate(answer):\n",
        "    # Split answer into words and calculate the number of unique words\n",
        "    words = answer.split()\n",
        "    unique_words = set(words)\n",
        "    return len(unique_words) / len(words)  # Return vocabulary rate\n",
        "\n",
        "# Calculate grammar rate and vocabulary rate in the user's answer\n",
        "grammar_rate = calculate_grammar_rate(user_answer)\n",
        "vocabulary_rate = calculate_vocabulary_rate(user_answer)\n",
        "\n",
        "print(\"Grammar Rate:\", grammar_rate)\n",
        "print(\"Vocabulary Rate:\", vocabulary_rate)\n",
        "\n",
        "# Predict the score for the new input text\n",
        "new_question = \"The bar chart below describes some changes about the percentage of people were born in Australia and who were born outside Australia living in urban, rural and town between 1995 and 2010. Summarise the information by selecting and reporting the main features and make comparisons where relevant.\"\n",
        "new_input_text = new_question + \" \" + user_answer\n",
        "new_input_seq = tokenizer.texts_to_sequences([new_input_text])\n",
        "new_input_pad = pad_sequences(new_input_seq, maxlen=500)  # Use the same maxlen as during training\n",
        "\n",
        "# Predict the score for the new input text\n",
        "predicted_score = model.predict(new_input_pad)\n",
        "print(\"Predicted Score:\", predicted_score[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqynaNPJLGVA",
        "outputId": "09d05c75-8e92-4812-e073-617e3d301750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "21/21 [==============================] - 14s 507ms/step - loss: 24.6328 - val_loss: 5.2211\n",
            "Epoch 2/20\n",
            "21/21 [==============================] - 10s 469ms/step - loss: 4.9828 - val_loss: 4.4576\n",
            "Epoch 3/20\n",
            "21/21 [==============================] - 10s 502ms/step - loss: 4.7556 - val_loss: 4.4650\n",
            "Epoch 4/20\n",
            "21/21 [==============================] - 10s 501ms/step - loss: 4.6981 - val_loss: 4.4213\n",
            "Epoch 5/20\n",
            "21/21 [==============================] - 11s 504ms/step - loss: 4.6166 - val_loss: 4.3691\n",
            "Epoch 6/20\n",
            "21/21 [==============================] - 11s 510ms/step - loss: 4.4719 - val_loss: 4.3011\n",
            "Epoch 7/20\n",
            "21/21 [==============================] - 9s 440ms/step - loss: 4.2509 - val_loss: 4.1955\n",
            "Epoch 8/20\n",
            "21/21 [==============================] - 11s 495ms/step - loss: 3.8917 - val_loss: 4.0960\n",
            "Epoch 9/20\n",
            "21/21 [==============================] - 11s 503ms/step - loss: 3.4812 - val_loss: 4.0260\n",
            "Epoch 10/20\n",
            "21/21 [==============================] - 11s 518ms/step - loss: 3.0804 - val_loss: 4.0305\n",
            "Epoch 11/20\n",
            "21/21 [==============================] - 10s 494ms/step - loss: 2.7615 - val_loss: 4.0999\n",
            "Epoch 12/20\n",
            "21/21 [==============================] - 9s 436ms/step - loss: 2.5501 - val_loss: 4.0888\n",
            "Epoch 13/20\n",
            "21/21 [==============================] - 10s 480ms/step - loss: 2.3603 - val_loss: 4.0681\n",
            "Epoch 14/20\n",
            "21/21 [==============================] - 10s 495ms/step - loss: 2.2075 - val_loss: 4.0956\n",
            "12/12 [==============================] - 1s 81ms/step\n",
            "Mean Absolute Error: 1.590172476665948\n",
            "Grammar Rate: 0.9781209781209781\n",
            "Vocabulary Rate: 0.504\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Predicted Score: 5.5967793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example user's answer\n",
        "user_answer = \"Rich countries often give money to poorer countries, but it does not solve poverty. Therefore, developed countries should give other types of help to the poor countries rather than financial aid. To what extent do you agree or disagree?\"\n",
        "\n",
        "# Preprocess user's answer\n",
        "preprocessed_user_answer = preprocess_text(user_answer)\n",
        "\n",
        "# Calculate vocabulary rate\n",
        "user_tokens = word_tokenize(preprocessed_user_answer)\n",
        "vocab_rate = len(set(user_tokens)) / len(user_tokens)\n",
        "\n",
        "# Predicted grammar rate (example with a random value)\n",
        "predicted_grammar_rate = np.random.uniform(0, 1)\n",
        "\n",
        "print(\"Vocabulary Rate:\", vocab_rate)\n",
        "print(\"Predicted Grammar Rate:\", predicted_grammar_rate)\n",
        "\n",
        "# Predict the score for the new input text\n",
        "new_question = \"While financial aid from wealthy nations to impoverished ones may seem ineffective in eradicating poverty, it remains a crucial lifeline for struggling economies. Alternative forms of assistance, such as technology transfer or educational programs, could supplement monetary aid. However, dismissing financial support entirely overlooks its immediate impact on basic needs like healthcare and infrastructure development. Therefore, a balanced approach integrating various forms of aid would better address the multifaceted challenges of poverty.\"\n",
        "new_input_text = new_question + \" \" + user_answer\n",
        "new_input_seq = tokenizer.texts_to_sequences([new_input_text])\n",
        "new_input_pad = pad_sequences(new_input_seq, maxlen=500)  # Use the same maxlen as during training\n",
        "\n",
        "# Predict the score for the new input text\n",
        "predicted_score = model.predict(new_input_pad)\n",
        "print(\"Predicted Score:\", predicted_score[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfOMARI_N916",
        "outputId": "87e6a2c4-a6b2-4f6a-b087-50d8bdeac58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar Rate: 0.9915254237288136\n",
            "Vocabulary Rate: 0.8974358974358975\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Predicted Score: 6.858673\n"
          ]
        }
      ]
    }
  ]
}